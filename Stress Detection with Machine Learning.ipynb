{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d37250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          subreddit post_id sentence_range  \\\n",
      "0              ptsd  8601tu       (15, 20)   \n",
      "1        assistance  8lbrx9         (0, 5)   \n",
      "2              ptsd  9ch1zh       (15, 20)   \n",
      "3     relationships  7rorpp        [5, 10]   \n",
      "4  survivorsofabuse  9p2gbc         [0, 5]   \n",
      "\n",
      "                                                text     id  label  \\\n",
      "0  He said he had not felt that way before, sugge...  33181      1   \n",
      "1  Hey there r/assistance, Not sure if this is th...   2606      0   \n",
      "2  My mom then hit me with the newspaper and it s...  38816      1   \n",
      "3  until i met my new boyfriend, he is amazing, h...    239      1   \n",
      "4  October is Domestic Violence Awareness Month a...   1421      1   \n",
      "\n",
      "   confidence  social_timestamp  social_karma  syntax_ari  ...  \\\n",
      "0         0.8        1521614353             5    1.806818  ...   \n",
      "1         1.0        1527009817             4    9.429737  ...   \n",
      "2         0.8        1535935605             2    7.769821  ...   \n",
      "3         0.6        1516429555             0    2.667798  ...   \n",
      "4         0.8        1539809005            24    7.554238  ...   \n",
      "\n",
      "   lex_dal_min_pleasantness  lex_dal_min_activation  lex_dal_min_imagery  \\\n",
      "0                     1.000                  1.1250                  1.0   \n",
      "1                     1.125                  1.0000                  1.0   \n",
      "2                     1.000                  1.1429                  1.0   \n",
      "3                     1.000                  1.1250                  1.0   \n",
      "4                     1.000                  1.1250                  1.0   \n",
      "\n",
      "   lex_dal_avg_activation  lex_dal_avg_imagery  lex_dal_avg_pleasantness  \\\n",
      "0                 1.77000              1.52211                   1.89556   \n",
      "1                 1.69586              1.62045                   1.88919   \n",
      "2                 1.83088              1.58108                   1.85828   \n",
      "3                 1.75356              1.52114                   1.98848   \n",
      "4                 1.77644              1.64872                   1.81456   \n",
      "\n",
      "   social_upvote_ratio  social_num_comments  syntax_fk_grade  sentiment  \n",
      "0                 0.86                    1         3.253573  -0.002742  \n",
      "1                 0.65                    2         8.828316   0.292857  \n",
      "2                 0.67                    0         7.841667   0.011894  \n",
      "3                 0.50                    5         4.104027   0.141671  \n",
      "4                 1.00                    1         7.910952  -0.204167  \n",
      "\n",
      "[5 rows x 116 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"stress.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6abc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit                   0\n",
      "post_id                     0\n",
      "sentence_range              0\n",
      "text                        0\n",
      "id                          0\n",
      "                           ..\n",
      "lex_dal_avg_pleasantness    0\n",
      "social_upvote_ratio         0\n",
      "social_num_comments         0\n",
      "syntax_fk_grade             0\n",
      "sentiment                   0\n",
      "Length: 116, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c10bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\GhostRider\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "data[\"text\"] = data[\"text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297823f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text      label\n",
      "0  said felt way sugget go rest trigger ahead you...     Stress\n",
      "1  hey rassist sure right place post goe  im curr...  No Stress\n",
      "2  mom hit newspap shock would know dont like pla...     Stress\n",
      "3  met new boyfriend amaz kind sweet good student...     Stress\n",
      "4  octob domest violenc awar month domest violenc...     Stress\n"
     ]
    }
   ],
   "source": [
    "data[\"label\"] = data[\"label\"].map({0: \"No Stress\", 1: \"Stress\"})\n",
    "data = data[[\"text\", \"label\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "081ef779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.array(data[\"text\"])\n",
    "y = np.array(data[\"label\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, \n",
    "                                                test_size=0.33, \n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992d8404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac294a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4d42c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Text: I am scared of not being able to get a job and repay my debt\n",
      "['No Stress']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665fe48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Text: I am scared of not fulfilling my dreams\n",
      "['No Stress']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d963114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
